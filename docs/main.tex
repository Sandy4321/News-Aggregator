\documentclass[a4paper, 14pt]{extarticle}
\usepackage{geometry}

\usepackage{cmap} % Улучшенный поиск русских слов в полученном pdf-файле
\usepackage{mathtext} % русские буквы в формулах
\defaulthyphenchar=127 % Если стоит до fontenc, то переносы не впишутся в выделяемый текст при 
%копировании его в буфер обмена
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english, russian]{babel}
\usepackage{pscyr}  
\renewcommand{\rmdefault}{ftm} % ftm - (TimesNewRoman), fac - Academy, fad - Advertisement, flz - 
%Lazurski, fcr - CourierNewPSM, others in pscyr.sty

\usepackage{amsthm,amsfonts,amsmath,amssymb,amscd} % Математические дополнения от AMS
\usepackage{mathtools} % Добавляет окружение multlined

\usepackage{longtable} % Длинные таблицы
\usepackage{multirow,makecell,array} % Улучшенное форматирование таблиц
\usepackage{booktabs} % Возможность оформления таблиц в классическом книжном стиле

\usepackage{soulutf8} % Поддержка переносоустойчивых подчёркиваний и зачёркиваний
\usepackage{icomma} % Запятая в десятичных дробях

\usepackage[usenames,dvipsnames,svgnames,table,rgb]{xcolor}

\usepackage{hyperref}

\usepackage{graphicx} % Подключаем пакет работы с графикой
\graphicspath{{../images/}{images/}} % Пути к изображениям

%%% Подписи %%%
\usepackage[singlelinecheck=off,center]{caption}
\usepackage{subcaption}

\usepackage[onehalfspacing]{setspace}

%%% Списки %%%
\usepackage{enumitem}

%%% Библиография %%%
\usepackage{cite} % Красивые ссылки на литературу

%%% Оглавление %%%
\usepackage[nottoc]{tocbibind}
\usepackage{tocloft}
\usepackage{titlesec}

\usepackage{titlesec} % Растояние между заголовками и текстом
\usepackage{float}
\usepackage{listings} % Listings

\usepackage{lipsum}

\input{styles} % Файл со стилями
\begin{document}
\include{cover_page} % Титульник
\include{abstract} % Аннотация
\include{table_of_content} % Оглавление 
% Тут комменты по всему:

\section{Введение}
% Неможко публицистическое введение, чтобы хорошо читалось
% ибо кроме введения обычно ничего не читают
С каждым годом вычислительные мощности современных компьютеров и сервисов, 
предлагающие облачные вычисления, позволяют 
обрабатывать всё большие массивы данных. Благодаря этому происходит быстрое 
развитие алгоритмов анализа данных и машинного обучения. Результат работы 
этих алгоритмов можно увидеть в нашей повседневной жизни: 
сервисы прогноза погоды, которые предсказывают направление движения 
облаков, персонализированная реклама, подстраивающиеся под 
интересы пользователя, автомобили с автопилотом и т.д. --- в основе всех 
этих разработок лежат алгоритмы интеллектуального анализа данных и 
машинного обучения.

Одна из важнейших проблем, возникающая перед исследователями и 
разработчиками подобных систем, заключается в поиске данных для обучения моделей,
которые в будущем будут использоваться для анализа новой информации.

Решением данной проблемы являются тексты из сети Интернет.
Петабайты информации, записанной на естественном языке за последние несколько 
десятилетий, доступны любому исследователю. Книги, новостные статьи, блоги, посты в 
социальных сетях --- всё это является источником легкодоступных данных.

Именно поэтому обработка естественного языка (Natrual Language Processing, 
NLP) получила большое развитие. За последние несколько лет появилось множество 
специализированных библиотек и сервисов для анализа естественного языка. К таким сервисам, 
например, относится IBM Watson --- набор платных продуктов, предлагающий различные
инструменты работы с текстом: от извлечения важной информации и 
классификации, до его генерации. %https://www.ibm.com/watson/
Яркими примерами свободнораспространяемых библиотек являются: NLTK, Gensim, MyStem,
pymorphy и многие другие.

В данной работе решаются две задачи:
\begin{enumerate}
	\item классификация тем новостных статей;
	\item агрегация новостных статей по смысловой близости.
\end{enumerate} 
Для придания работе новизны и оригинальности задача решается для русскоязычных новостей.

Практическая значимость работы доказывается на примере реализации в виде web-сервиса новостного агрегатора,
который в реальном времени, с помощью алгоритмов и подходов предложенных в данной работе,
обрабатывает публикации русскоязычных интернет-СМИ.

% Какие то общие слова, почему мы делаем этот агрегатор, какие у него будут функции.
\section{Цель и задачи курсовой работы}
Целью курсовой работы является разработка веб-сервиса, который:
\begin{enumerate}
	\item в реальном времени получает статьи из русскоязычных новостных источников;
	\item классифицирует полученные статьи по общим темам;
	\item агрегирует по схожести содержания статьи из различных источников.
\end{enumerate}
Агрегация и классификация основана на исследуемых в работе алгоритмы.

Для достижения поставленной цели, должны быть выполнены следующие задачи:
\begin{enumerate}
	\item Изучить методы и модели автоматической обработки текста и естественного языка;
	\item Собрать корпус новостных статей для обучения моделей;
	\item Исследовать и реализовать различные подходы к классификации и агрегации текстовых документов;
	\item Разработать back-end и front-end инфраструктуру сервиса.
\end{enumerate}

\section{Сбор и подготовка данных}
\subsection{Получение данных из новостных источников}
Для получения робастных моделей машинного обучения, требуется достаточно большой корпус новостных статей,
содержащий несколько сотен тысяч документов. Обычно существуют готовые коллекции текстов, но из-за выбранных 
ограничений к документам, а именно: новости на русском языке вместе с тег --- словом, описывающим тему 
документа, найти такой корпус не удалось, поэтому было принято решение собрать данные самостоятельно.

В качестве новостных источников были выбраны следующие популярные СМИ:
<<Газета.Ru>>, <<Lenta.ru>>, <<ТАСС>>, <<Новая Газета>>, <<ВЕДОМОСТИ>>, <<РИА Новости>> и <<СПОРТ-ЭКСПРЕСС>>.
Последнее было выбрано по причине малого количества спортивных новостей от других источников.

При анализе сайтов СМИ стало понятно, что они имеют схожую структуру: для отображения ссылок на статьи,
используются страницы со списком новостей (<<Лента новостей>>), по которым можно итерироваться,
изменяя параметры запросов, например, дату последней новости на странице или количество показанных статей.
Для извлечения данных из источников реализован набор алгоритмов, которые опираются на описанную структуру.

Стоит отметить, что во многих случаях для получения чистого текста приходится ждать ответа от сервера и обрабатывать 
HTML содержание страниц, что сильно замедляет работу, поэтому алгоритмы получения новостей одновременно обрабатывают
в параллельных процессах множество веб-страниц, что значительно ускоряет работу. Данные алгоритмы также используются в основном
web-сервисе для получения недавних новостей.

При формировании корпуса, все новостные статьи сопровождались различными метаданными: название СМИ, ссылка на статью,
дата публикации, тег и заголовок. В результате было получено более 1,1 млн. новостей с 1999 по 2017 год, многие из 
которых имели неправильно проставленные темы или не имели тем вовсе. Причин тому может быть несколько, например,
ошибки редакторов или технические ограничения веб-сайтов новостных агентств. Например, большинство новостей на сайте <<
Новой Газеты>> помечены тегом <<политика>>, что зачастую не совпадает с истинным содержанием статьи. После детального анализа тегов 
стало ясно, что относить новости к рубрикам редакторы стали только после определённого времени, а все уже имеющие 
статьи на сайте отнесли в <<политику>>. Некорректные данные пришлось удалить.

В итоговую выборку, которая в дальнейшем использовалась для обучения и тестирования алгоритмов,
вошло $133\,529$ статей, помеченных 32 различными тегами. Распределение СМИ и тем на отобранных данных отражено на 
рисунке \ref{media_topic_distr}.
\begin{figure}[h!]
	\centering
	\includegraphics[width=1\textwidth]{media_topi_distr.pdf}
	\caption{Распределение СМИ и тем в данных}
	\label{media_topic_distr}
\end{figure}

%\lipsum[3-4]
%Заменил препроцессинг на нормализацию
\subsection{Нормализация новостных статей}
Нормализация является одной из важнейших стадий обработки естественного языка. Не формально, нормализация приводит текст в 
более информативный для моделей вид. В зависимости от языка процесс нормализации может отличаться. Например, для русского языка
зачастую удаляют пунктуацию и стоп-слова, а также производят лемматизацию. Стоп-слова --- это слова, которые примерно 
одинаково распределены по всему корпусу языка, чаще всего ими являются местоимения, предлоги и союзы. Лемматизация --- 
приведение слова в начальную форму (лемма):
\begin{itemize}
	\item для существительных --- именительный падеж, единственное число;
	\item для прилагательных --- именительный падеж, единственное число, мужской род;
	\item для глаголов, причастий, деепричастий --- глагол в инфинитиве.
\end{itemize}

Часто вместо лемматизации используется стемминг --- алгоритм, который убирает части 
слова, влияющие на его форму, например, окончание. В результате применения данной процедуры однокоренные слова, как правило,
преобразуются к одинаковому виду. Данные алгоритмы не только опираются на словари, но и на 
определённые правила, зависящие от языка, так как в корпусе могут встречаться слова в разных формах, которых нет в 
словаре, например, неологизмы, но образованы они по правилам языка.

Процесс обработки текста в данной работе состоит из нескольких последовательных этапов:
\begin{enumerate}
	\item Приведение текста в нижний регистр.
	\item Удаление чисел и символов пунктуации. Дефис сохраняется.
	\item Удаление стоп-слов. В данный набор входят наиболее часто употребляемые слова русского и английского языков,
	а также названия новостных агентств (<<лента>>, <<тасс>>, <<риа>> и т.д.), сохранение которых приводит к 
	переобучению моделей.
	\item Лемматизация каждого слова с помощью библиотеки MyStem\footnote{\url{https://tech.yandex.ru/mystem/}}.
\end{enumerate}
%Исходный код конвеера можно найти в приложении. %TODO: добавить ссылку

\section{Классификация новостных статей}
За последние два десятка лет, в результате активных исследований в области машинного обучения,
было изобретено множество успешных алгоритмов классификации. Например, такие модели как support vector machines (SVM) \cite{weston99svms},
градиентный бустинг деревьев и нейронные сети \cite{DBLP:journals/corr/ConneauSBL16}, были успешно применены к задачам классификации текстов.
В данной работе для классификации новостных статей использовались две из перечисленных выше модели --- это SVM и градиентный бустинг
деревьев.

Анализ текста является важной частью машинного обучения, однако сырые данные, а именно последовательности символов переменной длины,
не могут быть переданы на вход алгоритму в явном виде т.к. большинство моделей ожидают численный вектор признаков фиксированной длинны.

Векторизация --- метод трансформации коллекции текстовых документов в числовые вектора признаков.
Существуют различные подходы к векторизации текста, в данной работе были применены два самых популярных: TF-IDF и word2vec.

\subsection{Линейная модель на TF-IDF признаках}
Одним из самых простых подходов к решению задачи классификации текстовых документов является обучение линейного классификатора на
TF-IDF признаках, посчитанных на корпусе документов.

TF-IDF --- статистическая мера, используемая для оценки важности слова в контексте 
документа, являющегося частью коллекции документов или корпуса.\cite{doi:10.1108/eb026526}
TF-IDF --- это произведение двух статистик: TF (term frequency) и IDF (inverse 
document frequency). На сегодняшний день, TF-IDF один из самых популярных способов взвешивания слов, входящих в корпус документов.
Например, 83\% рекомендательных систем цифровых библиотек используют TF-IDF \cite{Beel2016}.

Существует множество способов подсчёта TF-IDF, в данной работе использовался следующий:
$$
\text{tf}(t, d) = \cfrac{n_t}{\sum_{k} n_k},
$$
где $n_{t}$ есть число вхождений слова $t$ в документ, а $\sum_{k} n_k$ --- общее число слов в данном документе.
$$
\text{idf}(t, D) = \log{ \cfrac{|D|}{|\{ d_i \in D \mid t \in d_i \}|}},
$$
где $|D|$ --- число документов в корпусе, $|\{ d_i \in D \mid t \in d_i \}|$ — число документов из коллекции $D$, в которых встречается 
$t$ (когда $n_{t} \neq 0$).

Таким образом, мера TF-IDF является произведением двух сомножителей:
$$
\text{TF-IDF}(t, d, D) = \text{tf}(t, d) \cdot \text{idf}(t, D).
$$

Признаковым описанием одного объекта $d \in D$ будет вектор
$$
\big(\text{TF-IDF}(t,d,D)\big)_{t\in V},
$$
где $V$ --- словарь всех слов, встречающихся в коллекции $D$.

Для преобразования новостных статей в числовые признаки, использовался класс \verb+TfidfVectorizer+ из библиотеки машинного обучения Scikit-learn 
\cite{scikit-learn}. В качестве параметров векторизации использовались следующие значения: \verb+min_df=3+ --- учитываются слова, встретившиеся 
суммарно во всех документах минимум 3 раза и  \verb+ngram_range=(1,2)+~--- учитываются как отдельные слова, так и би-граммы.

После векторизации новостных статей, была получена разрежённая матрица размера $133\,529$ строк на $1\,025\,919$ столбцов. По причине большого 
количества признаков ($\gg$  обучающих примеров), в качестве классификатора было решено использовать линейный SVM. Не смотря на то, что данный 
алгоритм был впервые описан более пятидесяти лет назад, сегодня он по прежнему показывает одни из самых высоких результатов в задачах классификации 
текста. Как было показано в \cite{wang12simple}, особенно высокое качество удаётся получить при использовании би-грамм.

В данной работе в качестве SVM использовался \verb+SGDClassifier+ из библиотеки Scikit-learn. Данный класс реализует различные линейные
классификаторы, параметры которых оптимизируются с помощью алгоритма стохастического градиентного спуска \cite{Bottou2010}.

Классификатор обучался со следующими параметрами: \verb+loss="hinge"+~--- функционал качества линейного SVM,
\verb+n_iter=70+~--- число итераций оптимизационного алгоритма, \verb+alpha=1e-5+~--- коэффициент регуляризации.

Обучение классификатора происходило на $70\%$ новостных статей, остальные $30\%$ использовались для валидации.
Оценка качества классификации проводилась с помощью метрик accuracy и F1-меры с макро-усреднением по каждому классу.
На валидационном множестве линейному SVM удалось получить $\text{accuracy} = 0.8792$ и $\text{F1} = 0.8860$. Из матрицы ошибок,
приведённой на рисунке \ref{svm_confusion}, можно увидеть, что модель часто ошибается в классификации новостей на тему <<экономика>>, относя их
к новостям про <<бизнес>> (в $20\%$ случаев). Такая же ситуация характерна и для классов <<компании>>~-- <<бизнес>> ($12\%$), <<силовые 
структуры>>~-- <<оружие>> ($12\%$),  <<социальные сети>>~-- <<интернет>> ($15\%$), <<театр>>~-- <<кино>> ($9\%$). Перечисленные ошибки
являются, в основном, причиной семантической схожести классов, но зачастую одна и та же новость может содержать различные темы, поэтому,
возможно, нужно было решать данную задачу методами multilabel классификации, т.е. когда один объект может принадлежать сразу
нескольким классам. Напротив, среди всех тем выделяются несколько, которые классифицируются с высокой долей точности. Данные темы являются
узкоспециализированными и почти не имеют пересечения с другими. В основном это виды спорта, такие как <<футбол>> (точность $0.99$), <<хоккей>> 
($0.99$), <<формула-1>> ($1.00$), <<кибер-спорт>> ($0.98$) и т.д. Более детальные
значения метрик по каждому из классов можно найти на графике \ref{svm_classif_report}.

Веса признаков в линейной модели в случае, если признаки отмасштабированы, характеризуют степень их влияния на значение целевой переменной.
В задаче классификации текстов, кроме того, признаки являются хорошо интерпретируемыми, поскольку каждый из них соответствует конкретному слову,
поэтому из линейного SVM по каждому из классов были извлечены топ слова, для всех  32-ух тем (таблица \ref{table:topwords}). 






%Для определения этих метрик, введём следующие обозначения:
%
%TP (true postive)~--- число истинно-положительных значений.
%
%TN (true negative)~--- число истинно-отрицательных значений.
%
%FP (false positive)~--- число ложно-положительных значений.
%
%FN (false negative)~--- число ложно-отрицательных значений.
%
%$\text{precision (точность)} = \cfrac{TP}{TP + FP}$ --- насколько можно доверять классификатору.
%
%$\text{recall (полнота)} = \cfrac{TP}{TP + FN}$ --- как много объектов класса 1 находит классификатор.
%
%Тогда accuracy --- доля корректно классифицированных новостных статей от общего числа статей:
%$$
%\text{accuracy} = \cfrac{\text{TP} + \text{TN}}{\text{TP} + \text{TN} + \text{FP} + \text{FN}}.
%$$
%
%F1-мера --- гармоническое среднее точности и полноты
%$$
%\text{F1} = \cfrac{2 \cdot (\text{precision} \cdot \text{recall})}{\text{precision} + \text{recall}}.
%$$


\subsection{Градиентный бустинг деревьев на word2vec}
%\lipsum[3-4]
\section{Агрегация новостных статей}
\subsection{Кластеризация с помощью алгоритмов машинного обучения}
\subsection{Объединение в связные компоненты графа}
%\lipsum[3-4]
\section{Разработка веб-приложения}
Веб-приложение состоит из двух основных частей: back-end и front-end. Back-end -- это сам веб-сервер,
который осуществляет обработку запросов пользователей, получение и обработку данных.
Front-end -- это пользовательский интерфейс, визуализирующий полученные данные от back-end в понятный вид.
С помощью этого интерфейса пользователь способен ни только получать, но и передавать данные на back-end.
% \subsection{Back-end часть}
% \subsection{Front-end часть}

\section{Заключение}

\include{bibliography} % Список литературы

\setcounter{secnumdepth}{0}
\section{Приложение}
\begin{figure}[h!]
	\centering
	\includegraphics[width=1\textwidth]{svm_confusion_matrix.pdf}
	\caption{Матрица ошибок линейного SVM}
	\label{svm_confusion}
\end{figure}

\begin{figure*}[t!]
	\centering
	\begin{subfigure}[t]{0.5\textwidth}
		\centering
		\hspace*{-2cm}
		\includegraphics[width=1\textwidth]{svm_classif_report.pdf}
		\caption{Линейный SVM}
		\label{svm_classif_report}
	\end{subfigure}%
	~ 
	\begin{subfigure}[t]{0.5\textwidth}
		\centering
		\hspace*{-2cm}
		\includegraphics[width=1\textwidth]{lgb_w2v_bigartm_classif_report.pdf}
		\caption{LightGBM + w2v + bigARTM}
	\end{subfigure}
	\caption{Precision, Recall и F1 мера по каждому из классов}
\end{figure*}

\begin{table}[h]
	\resizebox{\textwidth}{!}{%
		\begin{tabular}{r|cccccccc}
			\toprule
			\textbf{animals}         &               жить &          вольер &             хозяин &              животный &               зоопарк &        питомец &           кличка &        животное \\
			\textbf{auto}            &          авторынок &           осаго &      автомобильный &     автопроизводитель &              автопром &          камаз &          автоваз &      автомобиль \\
			\textbf{basketball}      &                рфб &      евробаскет &          центровой &          кубок европа &             баскетбол &   баскетболист &         евролига &             нба \\
			\textbf{biathlon}        &           эстафета &    биатлонистка &            шипулин &                   сбр &            хохфильцен &        биатлон &              ibu &      биатлонист \\
			\textbf{books}           &         библиотека &    произведение &       писательница &                 роман &                 книга &   литературный &             поэт &        писатель \\
			\textbf{boxing}          &              алоян &          лебзяк &                мма &              поединок &              поветкин &            бой &             бокс &          боксер \\
			\textbf{business}        &   россельхознадзор &            fifa &                ржд &               газпром &           туроператор &        formula &         ритейлер &             оао \\
			\textbf{chess}           &            карякин &       шахматист &           карякина &                магнус &               шахматы &        карлсен &              фид &       шахматный \\
			\textbf{companies}       &  тысяча автомобиль &        компания &  миллиард кубометр &              миллиард &                тысяча &  процент акция &         ретейлер &         процент \\
			\textbf{cosmos}          &          космонавт &         светить &           прогресс &             вселенная &                космос &     астрофизик &             марс &       астронавт \\
			\textbf{crime}           &          грабитель &         изымать &        группировка &               полиция &               убивать &         летний &       преступник &          тюрьма \\
			\textbf{cybersport}      &             gaming &            team &              valve &           киберфутбол &                  dota &     киберспорт &  киберспортивный &  киберспортсмен \\
			\textbf{economics}       &               мрот &          греция &             бюджет &                пенсия &                   ввп &         минфин &        экономика &        инфляция \\
			\textbf{films}           &         мультфильм &          сериал &            актриса &                  кино &               картина &       режиссер &            актер &           фильм \\
			\textbf{football}        &               поле &         стадион &         нападающий &              матч тур &                  фифа &           уефа &        футболист &    полузащитник \\
			\textbf{forces}          &       развертывать &      выполнение &     военнослужащий &               военный &                 шойгу &        генштаб &       конашенков &      минобороны \\
			\textbf{formula1}        &              манор &      цитировать &               рено &               феррари &              макларен &          пилот &         мерседес &         формула \\
			\textbf{hockey}          &           авангард &             ска &              шайба &            нападающий &                хоккей &       хоккеист &              нхл &             кхл \\
			\textbf{internet}        &          википедия &          сервис &             ресурс &               youtube &                  сайт &          хакер &           блогер &        интернет \\
			\textbf{judiciary}       &             стража &          статья &       арестовывать &               колония &  следственный комитет &      следствие &              скр &  комитет россия \\
			\textbf{music}           &         композитор &     евровидение &              песня &                 певец &               концерт &         альбом &           певица &        музыкант \\
			\textbf{politics}        &              лидер &          кремль &      парламентарий &                партия &               депутат &        госдума &            глава &             мид \\
			\textbf{realty}          &             объект &    строительный &           жилищный &         строительство &                   жкх &        ипотека &            жилье &    недвижимость \\
			\textbf{religion}        &          монастырь &           собор &          церковный &                муфтий &                святой &       христиан &       митрополит &        патриарх \\
			\textbf{science}         &        университет &          журнал &          математик &                 физик &               научный &       археолог &    исследователь &          ученый \\
			\textbf{skiing}          &             вяльбе &          нортуг &             лыжник &                   fis &                легков &         йохауг &            лахти &         устюгов \\
			\textbf{social-networks} &          некоторые &            юзер &           facebook &               twitter &     пользователь сеть &   пользователь &        вконтакте &         соцсеть \\
			\textbf{technologies}    &          vimpelcom &           apple &           оператор &                  wifi &              говорить &            мтс &            робот &         контакт \\
			\textbf{tennis}          &    кубок федерация &            open &            шарапов &                теннис &                  корт &      теннисист &      теннисистка &     кубок дэвис \\
			\textbf{theatre}         &         росгосцирк &        цирковой &              балет &            постановка &           театральный &         мюзикл &            театр &       спектакль \\
			\textbf{volleyball}      &              факел &         маричев &             алекно &             суперлига &             казанский &      белогорье &      волейболист &        волейбол \\
			\textbf{weapons}         &               jane &  использоваться &       defense news &  министерство оборона &             миллиметр &  миллиметровый &          defense &             тип \\
			\bottomrule
	\end{tabular}}
	\caption{Слова с наибольшим весом по каждой теме (Веса из SVM)}
	\label{table:topwords}
\end{table}

\end{document}