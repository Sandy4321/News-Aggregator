\documentclass[a4paper, 14pt]{extarticle}
\usepackage{geometry}

\usepackage{cmap} % Улучшенный поиск русских слов в полученном pdf-файле
\usepackage{mathtext} % русские буквы в формулах
\defaulthyphenchar=127 % Если стоит до fontenc, то переносы не впишутся в выделяемый текст при 
%копировании его в буфер обмена
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english, russian]{babel}
\usepackage{pscyr}  
\renewcommand{\rmdefault}{ftm} % ftm - (TimesNewRoman), fac - Academy, fad - Advertisement, flz - 
%Lazurski, fcr - CourierNewPSM, others in pscyr.sty

\usepackage{amsthm,amsfonts,amsmath,amssymb,amscd} % Математические дополнения от AMS
\usepackage{mathtools} % Добавляет окружение multlined

\usepackage{longtable} % Длинные таблицы
\usepackage{multirow,makecell,array} % Улучшенное форматирование таблиц
\usepackage{booktabs} % Возможность оформления таблиц в классическом книжном стиле

\usepackage{soulutf8} % Поддержка переносоустойчивых подчёркиваний и зачёркиваний
\usepackage{icomma} % Запятая в десятичных дробях

\usepackage[usenames,dvipsnames,svgnames,table,rgb]{xcolor}

\usepackage{hyperref}

\usepackage{graphicx} % Подключаем пакет работы с графикой
\graphicspath{{../images/}{images/}} % Пути к изображениям

%%% Подписи %%%
\usepackage[singlelinecheck=off,center]{caption}
\usepackage{subcaption}

\usepackage[onehalfspacing]{setspace}

%%% Списки %%%
\usepackage{enumitem}

%%% Библиография %%%
\usepackage{cite} % Красивые ссылки на литературу

%%% Оглавление %%%
\usepackage[nottoc]{tocbibind}
\usepackage{tocloft}
\usepackage{titlesec}

\usepackage{titlesec} % Растояние между заголовками и текстом
\usepackage{float}
\usepackage{listings} % Listings

\usepackage{lipsum}

\input{styles} % Файл со стилями
\begin{document}
\include{cover_page} % Титульник
\include{abstract} % Аннотация
\include{table_of_content} % Оглавление 
\section{Введение}
% Какие то общие слова, почему мы делаем этот агрегатор, какие у него будут функции.
\section{Цель и задачи курсовой работы}
Целью курсовой работы является разработка веб-сервиса, который
\begin{enumerate}
	\item в реальном времени получает статьи из новостных источников;
	\item классифицирует полученные статьи по общим темам;
	\item агрегирует по схожести содержания статьи из различных источников.
\end{enumerate}
Последние два пункта должны быть автоматизированы с помощью алгоритмов анализа данных и машинного обучения.

Для достижения поставленной цели, должны быть выполнены следующие задачи:
\begin{enumerate}
	\item Изучить подходы автоматической обработки текста и естественного языка;
	\item Собрать корпус новостных статей для обучения моделей;
	\item Исследовать различные подходы к классификации и агрегации текстовых документов;
	\item Разработать back-end и front-end составляющие сервиса;
	\item Объединить результаты предыдущих пунктов в единый веб-сервис.
\end{enumerate}
\section{Сбор и подготовка данных}
\subsection{Получение данных из новостных источников}
Для получения робастных моделей машинного обучения, требуется достаточно большой корпус новостных статей,
содержащий порядка нескольких сотен тысяч документов. Кроме того, статьи должны быть русскоязычными, а также
содержать современную лексику и актуальную информацию, соответствующую состоянию дел в мире за последние 10-15 лет.
При детальном анализе Интернета, корпус, удовлетворяющий перечисленным требованиям, не был найден и, таким образом,
было решено собрать данные для исследования самостоятельно.

В качестве новостных источников были выбраны следующие популярные СМИ:
Газета.Ru, Lenta.ru, ТАСС, Новая Газета, ВЕДОМОСТИ и СПОРТ-ЭКСПРЕСС. Последнее было выбран по причине малого
количества спортивных новостей от других источников.

При формировании корпуса, все новостные статьи сопровождались различными метаданными, такими как ссылка на статью,
дата публикации и название СМИ. В результате было получено более 1,1 млн. новостей, многие из которых имели
неправильно проставленные темы. Причин тому может быть несколько, например, ошибки редакторов или технические ограничения
веб-сайтов новостных агентств. В итоговую выборку, которая в дальнейшем использовалась для обучения и тестирования алгоритмов
вошло 133 тыс. статей. Распределение СМИ и тем на отобранных данных отражено на рисунке \ref{media_topic_distr}.
\begin{figure}[h!]
	\centering
	\includegraphics[width=1\textwidth]{media_topi_distr.pdf}
	\caption{Распределение СМИ и тем в данных}
	\label{media_topic_distr}
\end{figure}

%\lipsum[3-4]
\subsection{Препроцессинг новостных статей}
Препроцессинг является одной из важнейших стадий анализа данных. В данной работе, обработка данных начинается уже
на этапе получения новостей: из них удаляются все лишние HTML, JSON и XML теги.

Основной конвеер обработки данных состоит из нескольких последовательных этапов:
\begin{enumerate}
	\item Приведение текста в нижний регистр.
	\item Удаление чисел и символов пунктуации. Дефис сохраняется.
	\item Удаление стоп-слов. В данный набор входят наиболее часто употребляемые слова русского и английского языков,
	а также названия новостных агентств (<<лента>>, <<тасс>>, <<риа>> и т.д.), сохранение которых приводит к переобучению моделей.
	\item Лемматизация каждого слова с помощью библиотеки MyStem\footnote{\url{https://tech.yandex.ru/mystem/}}.
\end{enumerate}
Исходный код конвеера можно найти в приложении. %TODO: добавить ссылку

%\lipsum[3-4]
\section{Классификация новостных статей}
%\lipsum[3-4]
\subsection{Линейная модель на TF-IDF признаках}
%\lipsum[3-4]
\subsection{Градиентный бустинг деревьев на word2vec}
%\lipsum[3-4]
\section{Агрегация новостных статей}
\subsection{Кластеризация с помощью алгоритмов машинного обучения}
\subsection{Объединение в связные компоненты графа}
%\lipsum[3-4]
\section{Разработка веб-приложения}
\subsection{Back-end часть}
\subsection{Front-end часть}
%\lipsum[3-4]
\section{Заключение}
%\lipsum[3-5]

\include{bibliography} % Список литературы

\setcounter{secnumdepth}{0}
\section{Приложение}
%\lipsum[3-5]

\end{document}